{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMNOYDB/7N3cHtJrJTYLkj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krahul2024/machine-learning/blob/main/tensors/tensors_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vMHC0Tbyt5Kj",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cfcc3b-69a8-4cb5-c9b1-3154bf37266f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import tensorflow_probability as tfp\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction - 0"
      ],
      "metadata": {
        "id": "EcI_fLLnvWCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensors with tf.constant\n",
        "scalar = tf.constant(10)\n",
        "print(scalar)\n",
        "scalar.ndim # this is for getting the dimension of tensor , here it is scalar\n"
      ],
      "metadata": {
        "id": "f2QQWFHTv-5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b3974f-91f8-4436-bc88-597b63c68bae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10, shape=(), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = tf.constant([10, 30])\n",
        "vector.ndim   # dimension of the vector , here it is 1"
      ],
      "metadata": {
        "id": "4XbkwnefwGOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6d6b4d-5b17-46eb-9b01-5b718283f7c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = tf.constant([[10, 22],[12,211]])\n",
        "print('No. of dimensions for matrix are : ', matrix.ndim)\n",
        "matrix # this is 2d so ndim -> no. of dimensions for this one will be 2"
      ],
      "metadata": {
        "id": "KilUoTuexKl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83cfb531-8fd5-49dc-f5d7-ac683c79d141"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of dimensions for matrix are :  2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 10,  22],\n",
              "       [ 12, 211]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " matrix_one = tf.constant([[10,11,12],[12,23,25],[1., 12., 122.]], dtype = tf.float32)\n",
        " matrix_one.ndim"
      ],
      "metadata": {
        "id": "oX6kia82xm1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c8e93c-6783-4450-aeff-73b4b351a60a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tensors with `tf.Variable`"
      ],
      "metadata": {
        "id": "NxDutNU34cit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var_tensor = tf.Variable([10,7])\n",
        "const_tensor = tf.constant([10,11])\n",
        "var_tensor , const_tensor\n",
        "rand_tensor = tf.random"
      ],
      "metadata": {
        "id": "SFCp6VTl4nX6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating random tensors with tensorflow\n",
        "\n",
        "`tf.random.uniform/normal( shape, minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None,  name=None)`\n",
        "\n",
        "uniform for uniform distribution,\n",
        "normal for normal distribution"
      ],
      "metadata": {
        "id": "c_SfTbcC7UZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_tensor = tf.random.uniform([2,5,3,4], minval = 0, maxval = 100, dtype = tf.dtypes.float32, seed = 11) # this is for getting uniformly distributed values\n",
        "rand_tensor, rand_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0618toIg5oe7",
        "outputId": "d86c903e-294a-4e9e-e188-eb8772e56334"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 5, 3, 4), dtype=float32, numpy=\n",
              " array([[[[36.499714  , 48.88778   , 91.32618   , 25.193262  ],\n",
              "          [16.582823  , 97.52257   , 44.004105  , 75.50574   ],\n",
              "          [63.21428   , 20.446682  , 21.20415   , 19.827986  ]],\n",
              " \n",
              "         [[27.02744   , 64.45725   , 15.8629055 , 89.46597   ],\n",
              "          [79.794586  , 19.316542  , 59.31648   , 51.863716  ],\n",
              "          [37.834156  , 14.249444  ,  0.78237057, 83.17368   ]],\n",
              " \n",
              "         [[62.441315  , 55.93804   , 18.659342  , 18.111538  ],\n",
              "          [31.55421   , 64.10766   ,  5.046737  , 14.97761   ],\n",
              "          [28.34264   , 91.52949   , 71.9794    , 99.49996   ]],\n",
              " \n",
              "         [[40.002274  , 49.299408  , 15.229475  , 89.02998   ],\n",
              "          [91.25129   , 44.708668  , 34.167706  , 80.94463   ],\n",
              "          [38.065636  , 33.97881   , 61.49669   , 74.61533   ]],\n",
              " \n",
              "         [[91.45552   , 47.018085  , 17.427181  , 30.804873  ],\n",
              "          [43.40054   , 37.342487  , 68.96394   , 28.43132   ],\n",
              "          [34.245228  , 99.00737   , 22.413242  , 58.96926   ]]],\n",
              " \n",
              " \n",
              "        [[[19.927002  , 59.582806  , 61.35932   , 14.36708   ],\n",
              "          [69.62731   , 90.41695   , 97.55304   , 30.635262  ],\n",
              "          [96.26891   , 99.26311   , 90.736244  ,  3.3309817 ]],\n",
              " \n",
              "         [[45.443142  , 71.994606  , 83.466545  , 30.089437  ],\n",
              "          [82.88392   , 11.479497  , 35.79887   , 58.623947  ],\n",
              "          [45.713852  ,  3.333974  , 96.5285    , 33.401287  ]],\n",
              " \n",
              "         [[ 8.043777  , 31.7137    , 80.0965    , 74.65399   ],\n",
              "          [52.91028   ,  8.250607  , 93.85097   , 10.573006  ],\n",
              "          [47.44301   , 58.200466  , 76.27761   , 32.822777  ]],\n",
              " \n",
              "         [[ 8.619154  , 93.13221   , 21.23642   , 54.26849   ],\n",
              "          [36.147926  , 28.163136  , 48.75045   , 50.119164  ],\n",
              "          [29.784023  , 85.95686   , 91.332436  , 35.88079   ]],\n",
              " \n",
              "         [[30.57394   , 89.54718   , 64.713776  , 42.370045  ],\n",
              "          [15.4685135 , 55.641747  ,  6.3193917 , 71.53642   ],\n",
              "          [92.82849   , 83.382095  , 79.17591   , 97.995056  ]]]],\n",
              "       dtype=float32)>,\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shuffling  \n",
        "`tf.random.shuffle(\n",
        "    value, seed=None, name=None\n",
        ")`\n",
        "\n",
        "This shuffles along the first dimension"
      ],
      "metadata": {
        "id": "WILIsth98z4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real = tf.constant([[10,122,1322],[12,612,322],[11, 212,102]])\n",
        "shuffled = tf.random.shuffle(real)\n",
        "shuffled, real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxW_93Hr_hJi",
        "outputId": "cec61516-8e1c-4eaf-ec8c-7b974ef4f94d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              " array([[  12,  612,  322],\n",
              "        [  10,  122, 1322],\n",
              "        [  11,  212,  102]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              " array([[  10,  122, 1322],\n",
              "        [  12,  612,  322],\n",
              "        [  11,  212,  102]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling is useful  in the cases when we have sequential data of different types .\n",
        "> let's say we have 100 images of first type , 100 images of second type, now if we feed this to NN , then it will learn first 100 and then rest, now using shuffling we can shuffle the order and mix both types of images and the model can learn simultaneously about both types of images."
      ],
      "metadata": {
        "id": "6TXqz11RB_Pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other ways of creating tensors"
      ],
      "metadata": {
        "id": "1UJ5KWs-_rca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.ones([2,3,4])  for all ones`\n",
        "\n",
        " `tf.zeros([5,3,4]) for all zeros  `\n",
        "\n",
        "> Also we can turn numpy arrays into tensors using various methods\n",
        "``tf.constant(np_arr)`` or `tf.convert_to_tensor(np_arr)` .\n",
        "\n",
        "> The difference between numpy arrays and tensors is , tensors can be run on a GPU.\n",
        "\n",
        "> Also we can change the shape , let's say there are total of 30 integers in np_arr , then we can get different shape of tensor as long as product of dimensions of new tensor is equal to the no. of elements in np array."
      ],
      "metadata": {
        "id": "ra6dEZ9MC3yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_arr = np.random.randint(100, size = ([5,3,4]))\n",
        "converted_tensor_same_dims = tf.convert_to_tensor(np_arr)\n",
        "converted_tensor_diff_dims = tf.constant(np_arr, shape = (2,3,2,5))\n",
        "converted_tensor_diff_dims, converted_tensor_diff_dims.ndim"
      ],
      "metadata": {
        "id": "sawtNzotC60M",
        "outputId": "777c205e-a83c-4f30-f46d-08ec32b7a85a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 3, 2, 5), dtype=int64, numpy=\n",
              " array([[[[ 6,  9, 14,  0, 12],\n",
              "          [31, 85, 42,  3, 60]],\n",
              " \n",
              "         [[ 1, 14, 71,  9, 52],\n",
              "          [18,  4, 57, 16, 12]],\n",
              " \n",
              "         [[72, 28, 78, 54, 52],\n",
              "          [28, 74, 19,  0, 55]]],\n",
              " \n",
              " \n",
              "        [[[99, 22, 34, 31, 54],\n",
              "          [70,  3, 61, 97, 79]],\n",
              " \n",
              "         [[ 0, 93, 92, 56, 83],\n",
              "          [72, 29, 17, 88, 55]],\n",
              " \n",
              "         [[58, 30, 50, 51, 77],\n",
              "          [17, 19, 83,  3, 79]]]])>,\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor properties\n",
        "* Shape : it is just information about different dimesions , like 2x4x5.\n",
        "* Rank : The no. of tensor dimensions , scalar -> 0, array/vector -> 1 , matrix -> 2 and so on ...\n",
        "* Axis  or Dimension  : A particular axis or dimension , indexing is from 0 , so for 0th -> x-axis  and 1st -> y-axis and so on ..\n",
        "* Size : This is total no. of elements  in the tensor"
      ],
      "metadata": {
        "id": "_R4X17r0E4AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rank 7 tensor\n",
        "rank_sev_tensor = tf.ones([2,3,4,2,3,4,2]) * 12\n",
        "print('Shape ' , rank_sev_tensor.shape)\n",
        "print('Rank ', rank_sev_tensor.ndim)\n",
        "print('Size ' , tf.size(rank_sev_tensor).numpy())\n",
        "for i in range(7):\n",
        "    print('No of elements along' , i+1 ,'th  axis : ', rank_sev_tensor.shape[i])\n",
        "\n",
        "print('\\nFirst two elements of each dimension ')\n",
        "rank_sev_tensor[:2, :2, :2, :2, :2, :2, :2]"
      ],
      "metadata": {
        "id": "XjVUAmNwHju8",
        "outputId": "7f8bf9f2-9e58-454c-c0cc-e8a31ac310e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape  (2, 3, 4, 2, 3, 4, 2)\n",
            "Rank  7\n",
            "Size  1152\n",
            "No of elements along 1 th  axis :  2\n",
            "No of elements along 2 th  axis :  3\n",
            "No of elements along 3 th  axis :  4\n",
            "No of elements along 4 th  axis :  2\n",
            "No of elements along 5 th  axis :  3\n",
            "No of elements along 6 th  axis :  4\n",
            "No of elements along 7 th  axis :  2\n",
            "\n",
            "First two elements of each dimension \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 2, 2, 2, 2, 2), dtype=float32, numpy=\n",
              "array([[[[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]],\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "        [[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]]],\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "       [[[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]],\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "        [[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding new dimension to our tensor\n",
        "> It just adds another dimension such that\n",
        "let's say original dimension is `3x4` then new dimension added makes the tensor have dimension as `3x4x1`."
      ],
      "metadata": {
        "id": "kNIyTkBMJEhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_two_tensor = tf.constant([[10,12,122],[11,519,102]])\n",
        "# converting or adding another dimension\n",
        "rank_three_tensor = rank_two_tensor[..., tf.newaxis]\n",
        "rank_two_tensor, rank_three_tensor"
      ],
      "metadata": {
        "id": "v27q96vIDhf3",
        "outputId": "92faac0f-8231-49a4-b9ab-67a92d8e505a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[ 10,  12, 122],\n",
              "        [ 11, 519, 102]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 3, 1), dtype=int32, numpy=\n",
              " array([[[ 10],\n",
              "         [ 12],\n",
              "         [122]],\n",
              " \n",
              "        [[ 11],\n",
              "         [519],\n",
              "         [102]]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative to `tf.newaxis`\n",
        "```\n",
        "tf.expand_dims(\n",
        "    input, axis, name=None\n",
        ")\n",
        "```\n",
        "we can expand along any of the dimension using it."
      ],
      "metadata": {
        "id": "l0mb9RoIDq0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_tensor = tf.expand_dims(rank_two_tensor, axis = -1) # expand the last or final axis\n",
        "expanded_tensor"
      ],
      "metadata": {
        "id": "_kV9uGZTDCzU",
        "outputId": "ef82541b-e55b-4007-d3fa-97b91c69c191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 1), dtype=int32, numpy=\n",
              "array([[[ 10],\n",
              "        [ 12],\n",
              "        [122]],\n",
              "\n",
              "       [[ 11],\n",
              "        [519],\n",
              "        [102]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor operations\n",
        "*Basic operations* : +, -, *, /"
      ],
      "metadata": {
        "id": "EFJ0cbZoD36f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tf.constant([[10,143],[121,940]])\n",
        "tensor + 10 , tensor - 11 , tensor * 6, tensor / 12, tensor * tensor , tf.multiply(tensor, 100)"
      ],
      "metadata": {
        "id": "tCIkP3jxMYCx",
        "outputId": "18b2e399-b44c-47aa-d346-265b6cb6e3b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              " array([[ 20, 153],\n",
              "        [131, 950]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              " array([[ -1, 132],\n",
              "        [110, 929]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              " array([[  60,  858],\n",
              "        [ 726, 5640]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
              " array([[ 0.83333333, 11.91666667],\n",
              "        [10.08333333, 78.33333333]])>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              " array([[   100,  20449],\n",
              "        [ 14641, 883600]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              " array([[ 1000, 14300],\n",
              "        [12100, 94000]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix multiplication\n",
        " *for matrix multiplication or dot product of two matrices  -> matrix_one * matrix_two ,\n",
        " let's say we have matrix_one  -> nxm,  matrix_two ->  axb,\n",
        "to calculate dot product of both matrices  ->  `''a == m'' ` must be true\n",
        "this gives us resultant matrix with dimension n x b\n",
        "If we do this matrix_one * matrix_two , this gives element wise multiplication in tensorflow,\n",
        "to get dot product,\n",
        " `tf.matmul` or `tf.tensordot()` is used*\n",
        "\n"
      ],
      "metadata": {
        "id": "FGpSW6VwM2S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tf.constant([[11,123, 31],[19,101,12],[5,38,21]])\n",
        "print(tensor * tensor , '\\n') # element wise multiplication\n",
        "# both of these can be used for matrix multiplication or dot product , keep in mind this example is square matrix but\n",
        "# multiplying the non-square matrix with itself for dot product , will give an error so it is better to multiply the matrix with transpose or reshape the matrix\n",
        "print('Matrix multiplication\\n', (tensor @ tensor).numpy(), '\\n') # this is from python\n",
        "print('Matrix multiplication\\n' ,tf.matmul(tensor, tensor ).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSuGIptDNZ8e",
        "outputId": "0a07c7d5-f8b7-47a7-9832-1bc3f19d6043"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  121 15129   961]\n",
            " [  361 10201   144]\n",
            " [   25  1444   441]], shape=(3, 3), dtype=int32) \n",
            "\n",
            "Matrix multiplication\n",
            " [[ 2613 14954  2468]\n",
            " [ 2188 12994  2053]\n",
            " [  882  5251  1052]] \n",
            "\n",
            "Matrix multiplication\n",
            " [[ 2613 14954  2468]\n",
            " [ 2188 12994  2053]\n",
            " [  882  5251  1052]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using reshape to adjust dimensions for non-square matrices\n",
        "> For matrices with more than 2 dimensions we need to choose an axis along which we have to transpose , like first or second or third and so on .......\n",
        "\n",
        "In case if the matrix multiplication doesn't work on some matrix then use transpose instead of reshape, check for differences between transpose and reshape outputs ."
      ],
      "metadata": {
        "id": "e_GP6JI8YrIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tf.constant([[11,123, 31],[19,101,12]])\n",
        "tensor_reshape = tf.reshape(tensor, shape = (3,2))\n",
        "print('Matrix Multiplication \\n', tf.matmul(tensor, tensor_reshape).numpy(), '\\n')\n",
        "tf.tensordot(tensor, tensor_reshape, axes = 1).numpy() # this requires axes also"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0-hQzcXYO0Q",
        "outputId": "9a7aea2c-e9b1-4df1-b692-4d76e15bb186"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication \n",
            " [[7065 4062]\n",
            " [4552 4400]] \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7065, 4062],\n",
              "       [4552, 4400]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the datatype of tensors"
      ],
      "metadata": {
        "id": "hdwJ4sjXev9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([1.2, 232.21,143.2])\n",
        "# a.dtype various types like going from lower size to higher -> reduced precision, and higher to lower  -> increased precision, from one datatype to another datatype\n",
        "# from float32 to float16\n",
        "b = tf.cast(a, dtype = tf.float16)\n",
        "b, b.dtype\n",
        "# similarly we can change from float32 to int32"
      ],
      "metadata": {
        "id": "H0n6CGu5eumV",
        "outputId": "2de13155-c6a6-4d3b-da5b-e3d5d2b3205d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=float16, numpy=array([  1.2, 232.2, 143.2], dtype=float16)>,\n",
              " tf.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregating tensors\n",
        "Condensing tensors from multiple values down to a smaller amount of values.\n",
        "> Note : Always use floats -> float16 or float32 while calculating absolute or statistical values."
      ],
      "metadata": {
        "id": "iooJbqWqfAGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the absolute values , note reduce is used as we are reducing the dimensions while calculating all these informations/ values\n",
        "c = tf.random.uniform(shape = [3,5], minval = -110, maxval = 100, seed = 100)\n",
        "print('Tensor \\n' , c.numpy())\n",
        "print('Max ', tf.reduce_max(c).numpy())\n",
        "print('Min ', tf.reduce_min(c).numpy())\n",
        "print('Mean ', tf.reduce_mean(c).numpy())\n",
        "print('Sum ', tf.reduce_sum(c).numpy())\n",
        "print('Standard deviation', tf.math.reduce_std(c).numpy())\n",
        "print('Variance ', tf.math.reduce_variance(c).numpy())\n",
        "print('Median ', tfp.stats.percentile(c, q = 50).numpy()) # use quartiles for calculation of median as median one is deprecated as of now\n",
        "print('Non - zero values', tf.math.count_nonzero(c).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkz4ZaHFgdV3",
        "outputId": "4966a2c1-7043-42fa-ddd7-c0d217cdea10"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor \n",
            " [[ 12.681183  -50.06677   -78.87486     2.4077225 -94.263885 ]\n",
            " [ 21.071808  -35.241364  -57.737095   49.185455   41.602158 ]\n",
            " [ 93.40146    20.605469   23.984833   97.24249   -49.169678 ]]\n",
            "Max  97.24249\n",
            "Min  -94.263885\n",
            "Mean  -0.21140544\n",
            "Sum  -3.1710815\n",
            "Standard deviation 56.889656\n",
            "Variance  3236.4329\n",
            "Median  12.681183\n",
            "Non - zero values 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding positional max or min"
      ],
      "metadata": {
        "id": "YgvgFmOAhU51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Max index \\n', tf.argmax(c).numpy()) # the axis by default is axis = 0, so it will give index of max values in each of the rows , so get the position just put the cordinate as 0,rest and you will get max"
      ],
      "metadata": {
        "id": "Y0ieXzf-rF91",
        "outputId": "29379ff8-5e71-4747-98fe-2e50cf8e0f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max index \n",
            " [2 2 2 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction - 1"
      ],
      "metadata": {
        "id": "1xQy4jK8rqSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing single dimensions"
      ],
      "metadata": {
        "id": "D9N_a8HtxDfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_tensor = tf.random.uniform(shape = [7,5,1,1,2])\n",
        "# new_tensor\n",
        "new_tensor_sq = tf.squeeze(new_tensor)\n",
        "new_tensor_sq.shape # this removes all the dimensions with 1 size , as there is no use of them"
      ],
      "metadata": {
        "id": "wHIOHeMKxJ3W",
        "outputId": "7a5b4103-dfae-4aae-b401-7f78319b3254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7, 5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One hot encoding"
      ],
      "metadata": {
        "id": "BCRBLiNOxVKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used for categorical data\n",
        "Explanation : [One hot encoding](https://chat.openai.com/share/03481a1e-8806-421f-808c-d71213764ea9)"
      ],
      "metadata": {
        "id": "J1CxpwRrGxii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = [1, 2, 3, 4,]\n",
        "tf.one_hot(tensor, depth = 8)  # using the one hot encoding function from tensorflow"
      ],
      "metadata": {
        "id": "jxCorpmykx5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.one_hot(tensor, depth = 4, on_value = 'this is tensor tutorial', off_value = 'another sentence') # this is random/custom encoding"
      ],
      "metadata": {
        "id": "cWUWsjyLlzw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors and Numpy\n",
        "* Tensorflow and numpy are beautiful combination.\n",
        "\n",
        "* Tensorflow is built on tensors\n",
        "*Numpy is built on arrays"
      ],
      "metadata": {
        "id": "GkcNZaBgmeeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tf.constant(np.array([12., 11, 52]))\n",
        "tensor"
      ],
      "metadata": {
        "id": "aLQJ-9GWnsv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = tf.constant(np.random.randint(-100, 100, size = [5,2,3,2]), shape = [5,2,3,2])\n",
        "random_tensor"
      ],
      "metadata": {
        "id": "pEQVtDssoLgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLQPj7vAonVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}