{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaJ/6GZRmnXvxrdWRpJkO8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krahul2024/machine-learning/blob/main/tensors/tensors_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "vMHC0Tbyt5Kj",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cdaa6df-cd89-4f58-ae89-85d585df779c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "EcI_fLLnvWCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensors with tf.constant\n",
        "scalar = tf.constant(10)\n",
        "print(scalar)\n",
        "scalar.ndim # this is for getting the dimension of tensor , here it is scalar\n"
      ],
      "metadata": {
        "id": "f2QQWFHTv-5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b95cfcd-70c6-429f-cb28-8981a3859f0f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10, shape=(), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = tf.constant([10, 30])\n",
        "vector.ndim   # dimension of the vector , here it is 1"
      ],
      "metadata": {
        "id": "4XbkwnefwGOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73c52f2-98d6-417f-e023-fc3ae101f79c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = tf.constant([[10, 22],[12,211]])\n",
        "print('No. of dimensions for matrix are : ', matrix.ndim)\n",
        "matrix # this is 2d so ndim -> no. of dimensions for this one will be 2"
      ],
      "metadata": {
        "id": "KilUoTuexKl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b0d1f1-6970-4b5b-f22e-08cff566363e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of dimensions for matrix are :  2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 10,  22],\n",
              "       [ 12, 211]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " matrix_one = tf.constant([[10,11,12],[12,23,25],[1., 12., 122.]], dtype = tf.float32)\n",
        " matrix_one.ndim"
      ],
      "metadata": {
        "id": "oX6kia82xm1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbbec80-e3ba-4f3c-ec82-3fc9208ec65f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tensors with `tf.Variable`"
      ],
      "metadata": {
        "id": "NxDutNU34cit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var_tensor = tf.Variable([10,7])\n",
        "const_tensor = tf.constant([10,11])\n",
        "var_tensor , const_tensor\n",
        "rand_tensor = tf.random"
      ],
      "metadata": {
        "id": "SFCp6VTl4nX6"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating random tensors with tensorflow\n",
        "\n",
        "`tf.random.uniform/normal( shape, minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None,  name=None)`\n",
        "\n",
        "uniform for uniform distribution,\n",
        "normal for normal distribution"
      ],
      "metadata": {
        "id": "c_SfTbcC7UZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_tensor = tf.random.uniform([2,5,3,4], minval = 0, maxval = 100, dtype = tf.dtypes.float32, seed = 11) # this is for getting uniformly distributed values\n",
        "rand_tensor, rand_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0618toIg5oe7",
        "outputId": "b12c92b2-4dcf-49dd-f382-3d68251618ea"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 5, 3, 4), dtype=float32, numpy=\n",
              " array([[[[99.17426   , 43.457474  , 74.8842    , 48.56793   ],\n",
              "          [92.41731   , 69.03195   ,  7.3939443 ,  5.887401  ],\n",
              "          [95.66044   ,  6.8011284 , 48.39058   , 72.129074  ]],\n",
              " \n",
              "         [[85.19228   , 24.99324   , 20.68056   , 73.96255   ],\n",
              "          [95.05777   , 48.89748   , 49.755836  , 69.14302   ],\n",
              "          [21.295761  , 74.53889   , 94.35124   , 20.163023  ]],\n",
              " \n",
              "         [[56.15524   , 33.069347  , 46.155537  , 48.076294  ],\n",
              "          [63.95413   , 75.65478   ,  9.761786  , 73.88579   ],\n",
              "          [24.63132   , 48.72495   , 75.65516   , 30.644775  ]],\n",
              " \n",
              "         [[79.64442   , 79.733864  , 81.45761   , 69.145325  ],\n",
              "          [38.53233   , 71.9818    , 18.157446  , 54.149174  ],\n",
              "          [28.692509  , 43.7253    , 68.49827   , 48.51942   ]],\n",
              " \n",
              "         [[36.78428   , 82.5075    , 61.040543  , 13.864792  ],\n",
              "          [67.056465  , 47.48404   , 78.96921   , 99.735245  ],\n",
              "          [53.922558  , 70.492615  , 23.0659    ,  5.710709  ]]],\n",
              " \n",
              " \n",
              "        [[[96.56588   , 84.75596   , 87.74865   , 29.279053  ],\n",
              "          [35.86434   , 58.47416   , 43.82515   , 37.364853  ],\n",
              "          [43.848812  , 23.537731  , 23.244213  , 33.949875  ]],\n",
              " \n",
              "         [[ 8.377445  , 28.61892   , 91.94051   , 81.5763    ],\n",
              "          [52.4706    , 46.58363   , 54.739296  , 59.477985  ],\n",
              "          [21.007454  , 53.245937  , 71.07542   , 25.996065  ]],\n",
              " \n",
              "         [[47.412346  ,  2.5363564 , 57.946766  , 67.3308    ],\n",
              "          [17.850101  , 81.560936  , 45.466064  , 37.132633  ],\n",
              "          [35.668434  , 35.64589   , 35.032475  , 71.400055  ]],\n",
              " \n",
              "         [[75.455605  , 79.63155   ,  7.9134583 , 92.827515  ],\n",
              "          [71.38807   , 57.739555  , 66.54509   , 98.58803   ],\n",
              "          [69.5905    , 38.985634  , 72.09591   , 69.47678   ]],\n",
              " \n",
              "         [[89.97154   , 33.53057   ,  0.10713339,  8.454334  ],\n",
              "          [27.436018  , 40.97805   , 52.198387  , 57.65823   ],\n",
              "          [35.29265   , 76.45978   , 84.27546   , 22.147083  ]]]],\n",
              "       dtype=float32)>,\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shuffling  \n",
        "`tf.random.shuffle(\n",
        "    value, seed=None, name=None\n",
        ")`\n",
        "\n",
        "This shuffles along the first dimension"
      ],
      "metadata": {
        "id": "WILIsth98z4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real = tf.constant([[10,122,1322],[12,612,322],[11, 212,102]])\n",
        "shuffled = tf.random.shuffle(real)\n",
        "shuffled, real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxW_93Hr_hJi",
        "outputId": "a94bf7be-5967-4251-96e6-7dc4898c1d18"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              " array([[  11,  212,  102],\n",
              "        [  10,  122, 1322],\n",
              "        [  12,  612,  322]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              " array([[  10,  122, 1322],\n",
              "        [  12,  612,  322],\n",
              "        [  11,  212,  102]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling is useful  in the cases when we have sequential data of different types .\n",
        "> let's say we have 100 images of first type , 100 images of second type, now if we feed this to NN , then it will learn first 100 and then rest, now using shuffling we can shuffle the order and mix both types of images and the model can learn simultaneously about both types of images."
      ],
      "metadata": {
        "id": "6TXqz11RB_Pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other ways of creating tensors"
      ],
      "metadata": {
        "id": "1UJ5KWs-_rca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.ones([2,3,4])  for all ones`\n",
        "\n",
        " `tf.zeros([5,3,4]) for all zeros  `\n",
        "\n",
        "> Also we can turn numpy arrays into tensors using various methods\n",
        "``tf.constant(np_arr)`` or `tf.convert_to_tensor(np_arr)` .\n",
        "\n",
        "> The difference between numpy arrays and tensors is , tensors can be run on a GPU.\n",
        "\n",
        "> Also we can change the shape , let's say there are total of 30 integers in np_arr , then we can get different shape of tensor as long as product of dimensions of new tensor is equal to the no. of elements in np array."
      ],
      "metadata": {
        "id": "ra6dEZ9MC3yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_arr = np.random.randint(100, size = ([5,3,4]))\n",
        "converted_tensor_same_dims = tf.convert_to_tensor(np_arr)\n",
        "converted_tensor_diff_dims = tf.constant(np_arr, shape = (2,3,2,5))\n",
        "converted_tensor_diff_dims, converted_tensor_diff_dims.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sawtNzotC60M",
        "outputId": "59c39a78-07bf-4973-ccdf-35111514d56c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 3, 2, 5), dtype=int64, numpy=\n",
              " array([[[[54, 75, 66, 62, 87],\n",
              "          [91, 52, 68, 38, 19]],\n",
              " \n",
              "         [[43,  0, 38, 94, 83],\n",
              "          [97,  9, 97, 24, 15]],\n",
              " \n",
              "         [[81, 72, 48, 29, 55],\n",
              "          [26, 15, 90, 17, 95]]],\n",
              " \n",
              " \n",
              "        [[[39,  3, 19, 60, 38],\n",
              "          [80, 48, 16, 61, 34]],\n",
              " \n",
              "         [[22, 53, 80, 90, 63],\n",
              "          [10,  0, 23, 71, 70]],\n",
              " \n",
              "         [[36, 55, 66, 72, 48],\n",
              "          [42, 23, 15, 19, 17]]]])>,\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor properties\n",
        "* Shape : it is just information about different dimesions , like 2x4x5.\n",
        "* Rank : The no. of tensor dimensions , scalar -> 0, array/vector -> 1 , matrix -> 2 and so on ...\n",
        "* Axis  or Dimension  : A particular axis or dimension , indexing is from 0 , so for 0th -> x-axis  and 1st -> y-axis and so on ..\n",
        "* Size : This is total no. of elements  in the tensor"
      ],
      "metadata": {
        "id": "_R4X17r0E4AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rank 7 tensor\n",
        "rank_sev_tensor = tf.ones([2,3,4,2,3,4,2]) * 12\n",
        "print('Shape ' , rank_sev_tensor.shape)\n",
        "print('Rank ', rank_sev_tensor.ndim)\n",
        "print('Size ' , tf.size(rank_sev_tensor).numpy())\n",
        "for i in range(7):\n",
        "    print('No of elements along' , i+1 ,'th  axis : ', rank_sev_tensor.shape[i])\n",
        "\n",
        "print('\\nFirst two elements of each dimension ')\n",
        "rank_sev_tensor[:2, :2, :2, :2, :2, :2, :2]"
      ],
      "metadata": {
        "id": "XjVUAmNwHju8",
        "outputId": "a6946e4a-ae47-4c2f-c4c1-ebe9a8c034aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape  (2, 3, 4, 2, 3, 4, 2)\n",
            "Rank  7\n",
            "Size  1152\n",
            "No of elements along 1 th  axis :  2\n",
            "No of elements along 2 th  axis :  3\n",
            "No of elements along 3 th  axis :  4\n",
            "No of elements along 4 th  axis :  2\n",
            "No of elements along 5 th  axis :  3\n",
            "No of elements along 6 th  axis :  4\n",
            "No of elements along 7 th  axis :  2\n",
            "\n",
            "First two elements of each dimension \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 2, 2, 2, 2, 2), dtype=float32, numpy=\n",
              "array([[[[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]],\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "        [[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]]],\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "       [[[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]],\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "        [[[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]],\n",
              "\n",
              "\n",
              "\n",
              "         [[[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]],\n",
              "\n",
              "\n",
              "          [[[12., 12.],\n",
              "            [12., 12.]],\n",
              "\n",
              "           [[12., 12.],\n",
              "            [12., 12.]]]]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNIyTkBMJEhP"
      },
      "execution_count": 96,
      "outputs": []
    }
  ]
}