{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krahul2024/machine-learning/blob/main/projects/next_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create model from scratch"
      ],
      "metadata": {
        "id": "8YD5WjRhNYov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "file_url = 'https://raw.githubusercontent.com/krahul2024/machine-learning/main/projects/Text-Datasets/paul_graham_essays.txt'\n",
        "content = requests.get(file_url).text\n",
        "len(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdI0p0vCwqTR",
        "outputId": "02d6af16-ae97-44e1-cc6f-58130a87b5cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3023219"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(list(set(content)))\n",
        "vocab_size, total_chars = len(vocab), len(content)\n",
        "vocab_size"
      ],
      "metadata": {
        "id": "Lfrjk7LH74Pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbbc100-ccad-4799-d96f-c630c95172b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports related to the model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uCt_YyxHkqxP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_index = dict((c, i) for i, c in enumerate(vocab))\n",
        "char_index"
      ],
      "metadata": {
        "id": "s2bVb8ErnQej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc46f91-c2bb-4548-c9c8-34af53bf3599"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '#': 4,\n",
              " '$': 5,\n",
              " '%': 6,\n",
              " '&': 7,\n",
              " \"'\": 8,\n",
              " '(': 9,\n",
              " ')': 10,\n",
              " '*': 11,\n",
              " '+': 12,\n",
              " ',': 13,\n",
              " '-': 14,\n",
              " '.': 15,\n",
              " '/': 16,\n",
              " '0': 17,\n",
              " '1': 18,\n",
              " '2': 19,\n",
              " '3': 20,\n",
              " '4': 21,\n",
              " '5': 22,\n",
              " '6': 23,\n",
              " '7': 24,\n",
              " '8': 25,\n",
              " '9': 26,\n",
              " ':': 27,\n",
              " ';': 28,\n",
              " '<': 29,\n",
              " '=': 30,\n",
              " '>': 31,\n",
              " '?': 32,\n",
              " '@': 33,\n",
              " 'A': 34,\n",
              " 'B': 35,\n",
              " 'C': 36,\n",
              " 'D': 37,\n",
              " 'E': 38,\n",
              " 'F': 39,\n",
              " 'G': 40,\n",
              " 'H': 41,\n",
              " 'I': 42,\n",
              " 'J': 43,\n",
              " 'K': 44,\n",
              " 'L': 45,\n",
              " 'M': 46,\n",
              " 'N': 47,\n",
              " 'O': 48,\n",
              " 'P': 49,\n",
              " 'Q': 50,\n",
              " 'R': 51,\n",
              " 'S': 52,\n",
              " 'T': 53,\n",
              " 'U': 54,\n",
              " 'V': 55,\n",
              " 'W': 56,\n",
              " 'X': 57,\n",
              " 'Y': 58,\n",
              " 'Z': 59,\n",
              " '[': 60,\n",
              " ']': 61,\n",
              " '^': 62,\n",
              " '_': 63,\n",
              " '`': 64,\n",
              " 'a': 65,\n",
              " 'b': 66,\n",
              " 'c': 67,\n",
              " 'd': 68,\n",
              " 'e': 69,\n",
              " 'f': 70,\n",
              " 'g': 71,\n",
              " 'h': 72,\n",
              " 'i': 73,\n",
              " 'j': 74,\n",
              " 'k': 75,\n",
              " 'l': 76,\n",
              " 'm': 77,\n",
              " 'n': 78,\n",
              " 'o': 79,\n",
              " 'p': 80,\n",
              " 'q': 81,\n",
              " 'r': 82,\n",
              " 's': 83,\n",
              " 't': 84,\n",
              " 'u': 85,\n",
              " 'v': 86,\n",
              " 'w': 87,\n",
              " 'x': 88,\n",
              " 'y': 89,\n",
              " 'z': 90,\n",
              " '{': 91,\n",
              " '|': 92,\n",
              " '}': 93,\n",
              " '\\x92': 94,\n",
              " '\\x96': 95,\n",
              " '\\x97': 96,\n",
              " '\\xa0': 97,\n",
              " '²': 98,\n",
              " 'à': 99,\n",
              " 'é': 100,\n",
              " 'ö': 101,\n",
              " '—': 102,\n",
              " '≈': 103,\n",
              " '⟨': 104,\n",
              " '⟩': 105}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 40\n",
        "steps = 3\n",
        "\n",
        "x , y = [], []\n",
        "for i in range(0, total_chars-input_size, steps):\n",
        "    x.append(content[i:i+input_size])\n",
        "    y.append(content[i+input_size])\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"{x[i]} -> {y[i]}\")\n",
        "\n",
        "print(f\"input-size : {len(x)}, output-size : {len(y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llVtZ1ISnlpV",
        "outputId": "aa0c96a0-8265-4fa3-b602-bbd5134da38f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Anyone can see they're not the same by ->  \n",
            "nyone can see they're not the same by th -> e\n",
            "ne can see they're not the same by the n -> u\n",
            "can see they're not the same by the numb -> e\n",
            " see they're not the same by the number  -> o\n",
            "e they're not the same by the number of  -> p\n",
            "hey're not the same by the number of peo -> p\n",
            "'re not the same by the number of people ->  \n",
            " not the same by the number of people wh -> o\n",
            "t the same by the number of people who a -> r\n",
            "input-size : 1007727, output-size : 1007727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros(\n",
        "    (\n",
        "         len(x),\n",
        "         input_size,\n",
        "         len(vocab)\n",
        "    ),\n",
        "    dtype =bool\n",
        ")\n",
        "\n",
        "Y = np.zeros(\n",
        "    (\n",
        "        len(x),\n",
        "        vocab_size\n",
        "    )\n",
        ")\n",
        "\n",
        "for i, seq in enumerate(x):\n",
        "  for j, char in enumerate(seq):\n",
        "    X[i, j, char_index[char]] = 1\n",
        "    Y[i, char_index[y[i]]] = 1\n",
        "\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "7d3Z2XQiovZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627b0bb3-3022-45c8-a018-0eb99de62965"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1007727, 40, 106), (1007727, 106))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0][0], Y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN0eATfg4WwO",
        "outputId": "36de42db-a443-4758-c3ed-e828946b14fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([False,  True, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.LSTM(128, input_shape = (input_size, vocab_size)),\n",
        "    keras.layers.Dense(\n",
        "        vocab_size, activation = 'softmax'\n",
        "    )\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    metrics = ['accuracy'],\n",
        "    loss = 'categorical_crossentropy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed-Z2Hoa5-xe",
        "outputId": "732b9a80-b65d-4ac8-ce26-5176e84a16dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 128)               120320    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 106)               13674     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133994 (523.41 KB)\n",
            "Trainable params: 133994 (523.41 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function which takes model and various parameters to train the model on given data\n",
        "def train(model_, input_data, output_data, batch_size = 128, validation_split = 0.05, verbose = 1, shuffle = True, epochs = 20):\n",
        "  training_history = model_.fit(\n",
        "      input_data, output_data, batch_size = batch_size,\n",
        "      validation_split = validation_split, verbose = verbose,\n",
        "      shuffle = shuffle, epochs = epochs\n",
        "  ).history\n",
        "\n",
        "  return model_, training_history"
      ],
      "metadata": {
        "id": "jwScGDtr9EYU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will divide the data into multiple parts and train each part seperately once training for one part is finished\n",
        "# This is to tackle the colab ram restrictions\n",
        "\n",
        "train_inputs = np.array_split(X, 10)\n",
        "train_outputs = np.array_split(Y, 10)\n",
        "\n",
        "train_inputs[0].shape, train_outputs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rBV78mz9VZa",
        "outputId": "86e6ca24-e848-490a-a889-eae8268e881a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100773, 40, 106), (100773, 106))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = train(model, train_inputs[0], train_outputs[0], epochs = 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df8XKZ5f_EjQ",
        "outputId": "c32f20ef-d8df-48f1-f537-a9d27db34204"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "748/748 [==============================] - 14s 10ms/step - loss: 2.8029 - accuracy: 0.2459 - val_loss: 2.5263 - val_accuracy: 0.3207\n",
            "Epoch 2/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 2.3970 - accuracy: 0.3303 - val_loss: 2.3722 - val_accuracy: 0.3461\n",
            "Epoch 3/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 2.2662 - accuracy: 0.3588 - val_loss: 2.2822 - val_accuracy: 0.3588\n",
            "Epoch 4/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 2.1848 - accuracy: 0.3750 - val_loss: 2.2184 - val_accuracy: 0.3697\n",
            "Epoch 5/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 2.1234 - accuracy: 0.3899 - val_loss: 2.1682 - val_accuracy: 0.3844\n",
            "Epoch 6/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 2.0735 - accuracy: 0.4025 - val_loss: 2.1240 - val_accuracy: 0.3999\n",
            "Epoch 7/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 2.0308 - accuracy: 0.4135 - val_loss: 2.0988 - val_accuracy: 0.4033\n",
            "Epoch 8/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.9933 - accuracy: 0.4235 - val_loss: 2.0604 - val_accuracy: 0.4094\n",
            "Epoch 9/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 1.9589 - accuracy: 0.4307 - val_loss: 2.0403 - val_accuracy: 0.4241\n",
            "Epoch 10/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.9278 - accuracy: 0.4383 - val_loss: 2.0159 - val_accuracy: 0.4239\n",
            "Epoch 11/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.8973 - accuracy: 0.4447 - val_loss: 1.9908 - val_accuracy: 0.4374\n",
            "Epoch 12/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.8698 - accuracy: 0.4506 - val_loss: 1.9710 - val_accuracy: 0.4295\n",
            "Epoch 13/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.8428 - accuracy: 0.4584 - val_loss: 1.9565 - val_accuracy: 0.4443\n",
            "Epoch 14/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.8175 - accuracy: 0.4636 - val_loss: 1.9295 - val_accuracy: 0.4431\n",
            "Epoch 15/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.7928 - accuracy: 0.4707 - val_loss: 1.9133 - val_accuracy: 0.4475\n",
            "Epoch 16/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.7713 - accuracy: 0.4762 - val_loss: 1.8971 - val_accuracy: 0.4572\n",
            "Epoch 17/40\n",
            "748/748 [==============================] - 6s 7ms/step - loss: 1.7492 - accuracy: 0.4824 - val_loss: 1.8832 - val_accuracy: 0.4552\n",
            "Epoch 18/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.7301 - accuracy: 0.4889 - val_loss: 1.8655 - val_accuracy: 0.4650\n",
            "Epoch 19/40\n",
            "748/748 [==============================] - 4s 6ms/step - loss: 1.7128 - accuracy: 0.4940 - val_loss: 1.8566 - val_accuracy: 0.4626\n",
            "Epoch 20/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 1.6938 - accuracy: 0.4993 - val_loss: 1.8423 - val_accuracy: 0.4687\n",
            "Epoch 21/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.6764 - accuracy: 0.5045 - val_loss: 1.8317 - val_accuracy: 0.4783\n",
            "Epoch 22/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 1.6601 - accuracy: 0.5093 - val_loss: 1.8268 - val_accuracy: 0.4826\n",
            "Epoch 23/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 1.6461 - accuracy: 0.5128 - val_loss: 1.8199 - val_accuracy: 0.4737\n",
            "Epoch 24/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.6303 - accuracy: 0.5172 - val_loss: 1.8015 - val_accuracy: 0.4789\n",
            "Epoch 25/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 1.6160 - accuracy: 0.5218 - val_loss: 1.8132 - val_accuracy: 0.4844\n",
            "Epoch 26/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.6026 - accuracy: 0.5244 - val_loss: 1.8061 - val_accuracy: 0.4801\n",
            "Epoch 27/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.5905 - accuracy: 0.5291 - val_loss: 1.7887 - val_accuracy: 0.4898\n",
            "Epoch 28/40\n",
            "748/748 [==============================] - 6s 8ms/step - loss: 1.5784 - accuracy: 0.5327 - val_loss: 1.7827 - val_accuracy: 0.4856\n",
            "Epoch 29/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.5666 - accuracy: 0.5349 - val_loss: 1.7919 - val_accuracy: 0.4892\n",
            "Epoch 30/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.5547 - accuracy: 0.5393 - val_loss: 1.7748 - val_accuracy: 0.4892\n",
            "Epoch 31/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.5430 - accuracy: 0.5426 - val_loss: 1.7611 - val_accuracy: 0.4995\n",
            "Epoch 32/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.5336 - accuracy: 0.5455 - val_loss: 1.7683 - val_accuracy: 0.4979\n",
            "Epoch 33/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.5219 - accuracy: 0.5488 - val_loss: 1.7618 - val_accuracy: 0.5005\n",
            "Epoch 34/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.5130 - accuracy: 0.5506 - val_loss: 1.7592 - val_accuracy: 0.4979\n",
            "Epoch 35/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.5024 - accuracy: 0.5539 - val_loss: 1.7559 - val_accuracy: 0.5027\n",
            "Epoch 36/40\n",
            "748/748 [==============================] - 6s 7ms/step - loss: 1.4941 - accuracy: 0.5554 - val_loss: 1.7546 - val_accuracy: 0.5053\n",
            "Epoch 37/40\n",
            "748/748 [==============================] - 5s 7ms/step - loss: 1.4848 - accuracy: 0.5593 - val_loss: 1.7572 - val_accuracy: 0.5015\n",
            "Epoch 38/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.4766 - accuracy: 0.5617 - val_loss: 1.7545 - val_accuracy: 0.5047\n",
            "Epoch 39/40\n",
            "748/748 [==============================] - 6s 7ms/step - loss: 1.4680 - accuracy: 0.5637 - val_loss: 1.7394 - val_accuracy: 0.5066\n",
            "Epoch 40/40\n",
            "748/748 [==============================] - 5s 6ms/step - loss: 1.4602 - accuracy: 0.5650 - val_loss: 1.7454 - val_accuracy: 0.5007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('next_char.keras')"
      ],
      "metadata": {
        "id": "wWWxK3kNCbgq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improve the model"
      ],
      "metadata": {
        "id": "5vs7_WizNqOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. Load the content and model\n",
        "2. Divide the data into multiple parts\n",
        "3. Train one part at a time\n",
        "4. Save the model upto that training\n",
        "5. Continue training the model for other parts\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "c2hRHa-kNzTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}