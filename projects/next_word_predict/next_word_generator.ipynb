{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXYtFCXmC/6Wc742PhtEW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krahul2024/machine-learning/blob/main/projects/next_word_predict/next_word_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import tensorflow as tf,  pandas as pd, numpy as np, nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "fpBWBI98kh6f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "rdxRnxfSl5iY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "\n",
        "text_data = ' '.join(brown.words())\n",
        "len(text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHxun66dmIio",
        "outputId": "d1b3b16a-246c-4353-83ef-fa07da3cbdfa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6127073"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign each word a number, as this helps in generating the outputs\n",
        "\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "indexes = tokenizer.word_index\n",
        "len(indexes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOfWGugQqESa",
        "outputId": "6306f0ed-8df1-474b-a846-af3efca4c4f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44541"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "sents = nltk.sent_tokenize(text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20esk6CBqYwx",
        "outputId": "30217bbd-4ab0-4dd0-81a7-790658ca7b16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "From all these single word tokens and sentence tokens what we have to create now is ,\n",
        "let's say a sentence  .... this is cat and it is blue .... this : 23, is : 32, cat : 433  and so on....--> word : index\n",
        "then we have to prepare the dataset as shown below,\n",
        "\n",
        "this -> is\n",
        "this is -> cat\n",
        "this is cat -> and\n",
        "this is cat and -> it\n",
        "....\n",
        "\n",
        "this is how our prediction works when we type in the keyboard,\n",
        "just that now in place of these words we have to generate the dataset in terms of indexes of these words in our list of word\n",
        "indexes , as computer don't understand the english languages, heck they don't even understand string just numbers.\n",
        "'''\n",
        "# converting the sentences which are made up of words into group of indexes of the words they are made up of\n",
        "x, y = [], []\n",
        "for sent in sents :\n",
        "    sent_tokens = tokenizer.texts_to_sequences([sent])[0]\n",
        "    for i in range(1, len(sent_tokens)):\n",
        "        input_seq = sent_tokens[:i+1]\n",
        "        x.append(input_seq[:-1])\n",
        "        y.append(input_seq[-1])\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFy5x0g5tERm",
        "outputId": "7980694b-c2c7-402f-e70d-3ce69e2fe166"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-7d6ced0ce831>:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x = np.array(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(x[i], '--->', y[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EalgWIv9ybjA",
        "outputId": "41309c32-60f8-4716-dd2d-dab80be6f5c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] ---> 5514\n",
            "[1, 5514] ---> 658\n",
            "[1, 5514, 658] ---> 2189\n",
            "[1, 5514, 658, 2189] ---> 1652\n",
            "[1, 5514, 658, 2189, 1652] ---> 55\n",
            "[1, 5514, 658, 2189, 1652, 55] ---> 1901\n",
            "[1, 5514, 658, 2189, 1652, 55, 1901] ---> 30\n",
            "[1, 5514, 658, 2189, 1652, 55, 1901, 30] ---> 2220\n",
            "[1, 5514, 658, 2189, 1652, 55, 1901, 30, 2220] ---> 2\n",
            "[1, 5514, 658, 2189, 1652, 55, 1901, 30, 2220, 2] ---> 14185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have to find the longest sentence and then make each array of that length by padding some value: 0, because when we\n",
        "# do the training then we need constant size of the matrix or the input size should be consistent\n",
        "max_len = max([len(arr) for arr in x])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3-vIyRzzGQA",
        "outputId": "66aeccdb-78dd-4c51-cbc0-0b85a5be9ed0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pad_seq = pad_sequences(x, maxlen = max_len, padding = 'pre') # padding at the begining because we don't have anything indexed with 0 and also we don't want to output nothing.\n",
        "pad_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7jdEjvc1GXI",
        "outputId": "e298e6db-1660-4fcb-a2ba-30cc27a52cdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,     0,     0,     1],\n",
              "       [    0,     0,     0, ...,     0,     1,  5514],\n",
              "       [    0,     0,     0, ...,     1,  5514,   658],\n",
              "       ...,\n",
              "       [    0,     0,     0, ..., 11491,  2596, 44540],\n",
              "       [    0,     0,     0, ...,  2596, 44540,  1681],\n",
              "       [    0,     0,     0, ..., 44540,  1681,     9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pad_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk13C_6m1aQh",
        "outputId": "675d8ee4-e856-4fb4-e036-a027d393b8bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "979759"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can treat this problem as classification problem not a regression task, thus we have to transform the output using one-hot encoding\n",
        "y = tf.keras.utils.to_categorical(y, num_classes = len(indexes)+1)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox61SidL2SLD",
        "outputId": "92d5f5fa-0175-4643-9347-f81d492f6665"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(979759, 44542)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWNF2xMv5AKD"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}