{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwk/QX4ZnPwqYUk7iY3eTK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krahul2024/machine-learning/blob/main/code/text_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdRfG2BMeUWc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import seaborn as sns\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/datasets' # current location is drive/datasets/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Processing"
      ],
      "metadata": {
        "id": "hXBU-K7bfeMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Term frequency : frequency of term/ no. of terms in the document\n",
        "\n",
        "* Inverse document frequency : log(N/n) ,\n",
        "N -> no. of documents\n",
        "n -> no. of documents the term has occured"
      ],
      "metadata": {
        "id": "qFT8O51jfgwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words('english'))\n",
        "fake_data = pd.read_csv('fake_news_dataset.csv')\n",
        "fake_data.head(10)"
      ],
      "metadata": {
        "id": "IumEksM3e13g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing"
      ],
      "metadata": {
        "id": "9AdS87Hcg_hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_data.isnull().sum()"
      ],
      "metadata": {
        "id": "LcX-5KPsgVq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_data = fake_data.fillna('')  # removing the null values\n",
        "fake_data['content'] = fake_data['author'] + ' ' + fake_data['title']\n",
        "fake_data['content']"
      ],
      "metadata": {
        "id": "RXt--euqhLpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = fake_data.drop('label', axis = 1)\n",
        "y = fake_data['label']\n",
        "x.head()"
      ],
      "metadata": {
        "id": "ibu3xPMfk1ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZoVFwHOlakQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}