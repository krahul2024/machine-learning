{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxePLPUuNwAczNFneozYdK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krahul2024/machine-learning/blob/main/molecule_props.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7tVEQOhUx-rK"
      },
      "outputs": [],
      "source": [
        "#@title Installs and Imports\n",
        "!pip install torch-geometric\n",
        "import torch_geometric\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from pathlib import Path\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.nn import GCNConv, GINConv, global_mean_pool, global_add_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loading the dataset\n",
        "\n",
        "# setting the location of content\n",
        "data_path = '/content/data'\n",
        "print(data_path)\n",
        "\n",
        "# load the dataset\n",
        "qm_nine = QM9(root = data_path)\n",
        "qm_nine[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "lbFT3BIGyz_g",
        "outputId": "237bedad-1fb6-4bed-db25-7c1848aceedd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
            "Extracting /content/data/raw/qm9_v3.zip\n",
            "Processing...\n",
            "Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[5, 11], edge_index=[2, 8], edge_attr=[8, 4], y=[1, 19], pos=[5, 3], idx=[1], name='gdb_1', z=[5])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the dataset has many regression targets, we will only focus on one of the tasks, which is the prediction of the dipole moment . For this tutorial, we only sample a subset of QM9. This keeps the runtime low and this is still enough to show some first results. The dataset is split into training, validation and test sets with a  split ratio. In addition, we normalize the training data () and apply the same mean and standard deviation to the test and validation set."
      ],
      "metadata": {
        "id": "7ZJ589nw1b3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset proprocessing\n",
        "target = pd.DataFrame(qm_nine.data.y.numpy())\n",
        "qm_nine.data.y = torch.Tensor(target[0])\n",
        "qm_nine = qm_nine.shuffle()\n",
        "\n",
        "#split the dataset\n",
        "size = 10000\n",
        "train_idx = int(size * 0.8)\n",
        "test_idx = int(size * 0.12)\n",
        "val_idx = size * 0.8\n",
        "\n",
        "\n",
        "# normalization of the dataset\n",
        "data_mean = qm_nine.data.y[0:train_idx].mean()\n",
        "data_std = qm_nine.data.y[0:train_idx].std()\n",
        "qm_nine.data.y = (qm_nine.data.y - data_mean) / data_std\n",
        "\n",
        "\n",
        "# function for loading the dataset into loader\n",
        "def load_data(data_, start_idx, end_idx, batch_size = 64, shuffle = True):\n",
        "  return DataLoader(\n",
        "      qm_nine[start_idx: end_idx+1], batch_size = batch_size,\n",
        "      shuffle = shuffle\n",
        "  )\n",
        "\n",
        "train_loader = load_data(qm_nine, 0, train_idx)\n",
        "test_loader = load_data(qm_nine, train_idx+1, train_idx+test_idx+1)\n",
        "val_loader = load_data(qm_nine, train_idx + test_idx+1, train_idx+ test_idx + val_idx+1)"
      ],
      "metadata": {
        "id": "YBNxXZZP0QK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GCN implementation\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    \"\"\"Graph Convolutional Network class with 3 convolutional layers and a linear layer\"\"\"\n",
        "\n",
        "    def __init__(self, dim_h):\n",
        "        \"\"\"init method for GCN\n",
        "\n",
        "        Args:\n",
        "            dim_h (int): the dimension of hidden layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(qm9.num_features, dim_h)\n",
        "        self.conv2 = GCNConv(dim_h, dim_h)\n",
        "        self.conv3 = GCNConv(dim_h, dim_h)\n",
        "        self.lin = torch.nn.Linear(dim_h, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        e = data.edge_index\n",
        "        x = data.x\n",
        "\n",
        "        x = self.conv1(x, e)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, e)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, e)\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "\n",
        "        x = Fun.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "TUiz_Rb61xXx",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GIN implementation\n",
        "class GIN(torch.nn.Module):\n",
        "    \"\"\"Graph Isomorphism Network class with 3 GINConv layers and 2 linear layers\"\"\"\n",
        "\n",
        "    def __init__(self, dim_h):\n",
        "        \"\"\"Initializing GIN class\n",
        "\n",
        "        Args:\n",
        "            dim_h (int): the dimension of hidden layers\n",
        "        \"\"\"\n",
        "        super(GIN, self).__init__()\n",
        "        self.conv1 = GINConv(\n",
        "            Sequential(Linear(11, dim_h), BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU())\n",
        "        )\n",
        "        self.conv2 = GINConv(\n",
        "            Sequential(\n",
        "                Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
        "            )\n",
        "        )\n",
        "        self.conv3 = GINConv(\n",
        "            Sequential(\n",
        "                Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
        "            )\n",
        "        )\n",
        "        self.lin1 = Linear(dim_h, dim_h)\n",
        "        self.lin2 = Linear(dim_h, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = data.x\n",
        "        edge_index = data.edge_index\n",
        "        batch = data.batch\n",
        "\n",
        "        # Node embeddings\n",
        "        h = self.conv1(x, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv2(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv3(h, edge_index)\n",
        "\n",
        "        # Graph-level readout\n",
        "        h = global_add_pool(h, batch)\n",
        "\n",
        "        h = self.lin1(h)\n",
        "        h = h.relu()\n",
        "        h = Fun.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.lin2(h)\n",
        "\n",
        "        return h"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rGYOSNjfFe3c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training  and Validation functions\n",
        "def training(loader, model, loss, optimizer):\n",
        "    \"\"\"Training one epoch\n",
        "\n",
        "    Args:\n",
        "        loader (DataLoader): loader (DataLoader): training data divided into batches\n",
        "        model (nn.Module): GNN model to train on\n",
        "        loss (nn.functional): loss function to use during training\n",
        "        optimizer (torch.optim): optimizer during training\n",
        "\n",
        "    Returns:\n",
        "        float: training loss\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "\n",
        "    current_loss = 0\n",
        "    for d in loader:\n",
        "        optimizer.zero_grad()\n",
        "        d.x = d.x.float()\n",
        "\n",
        "        out = model(d)\n",
        "\n",
        "        l = loss(out, torch.reshape(d.y, (len(d.y), 1)))\n",
        "        current_loss += l / len(loader)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "    return current_loss, model\n",
        "\n",
        "\n",
        "\n",
        "def validation(loader, model, loss):\n",
        "    \"\"\"Validation\n",
        "\n",
        "    Args:\n",
        "        loader (DataLoader): validation set in batches\n",
        "        model (nn.Module): current trained model\n",
        "        loss (nn.functional): loss function\n",
        "\n",
        "    Returns:\n",
        "        float: validation loss\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    for d in loader:\n",
        "        out = model(d)\n",
        "        l = loss(out, torch.reshape(d.y, (len(d.y), 1)))\n",
        "        val_loss += l / len(loader)\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "K3cFXpILFgw-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Testing and others\n",
        "@torch.no_grad()\n",
        "def testing(loader, model):\n",
        "    \"\"\"Testing\n",
        "\n",
        "    Args:\n",
        "        loader (DataLoader): test dataset\n",
        "        model (nn.Module): trained model\n",
        "\n",
        "    Returns:\n",
        "        float: test loss\n",
        "    \"\"\"\n",
        "    loss = torch.nn.MSELoss()\n",
        "    test_loss = 0\n",
        "    test_target = numpy.empty((0))\n",
        "    test_y_target = numpy.empty((0))\n",
        "    for d in loader:\n",
        "        out = model(d)\n",
        "        # NOTE\n",
        "        # out = out.view(d.y.size())\n",
        "        l = loss(out, torch.reshape(d.y, (len(d.y), 1)))\n",
        "        test_loss += l / len(loader)\n",
        "\n",
        "        # save prediction vs ground truth values for plotting\n",
        "        test_target = numpy.concatenate((test_target, out.detach().numpy()[:, 0]))\n",
        "        test_y_target = numpy.concatenate((test_y_target, d.y.detach().numpy()))\n",
        "\n",
        "    return test_loss, test_target, test_y_target\n",
        "\n",
        "\n",
        "def train_epochs(epochs, model, train_loader, val_loader, path):\n",
        "    \"\"\"Training over all epochs\n",
        "\n",
        "    Args:\n",
        "        epochs (int): number of epochs to train for\n",
        "        model (nn.Module): the current model\n",
        "        train_loader (DataLoader): training data in batches\n",
        "        val_loader (DataLoader): validation data in batches\n",
        "        path (string): path to save the best model\n",
        "\n",
        "    Returns:\n",
        "        array: returning train and validation losses over all epochs, prediction and ground truth values for training data in the last epoch\n",
        "    \"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    loss = torch.nn.MSELoss()\n",
        "\n",
        "    train_target = numpy.empty((0))\n",
        "    train_y_target = numpy.empty((0))\n",
        "    train_loss = numpy.empty(epochs)\n",
        "    val_loss = numpy.empty(epochs)\n",
        "    best_loss = math.inf\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss, model = training(train_loader, model, loss, optimizer)\n",
        "        v_loss = validation(val_loader, model, loss)\n",
        "        if v_loss < best_loss:\n",
        "            torch.save(model.state_dict(), path)\n",
        "        for d in train_loader:\n",
        "            out = model(d)\n",
        "            if epoch == epochs - 1:\n",
        "                # record truly vs predicted values for training data from last epoch\n",
        "                train_target = numpy.concatenate((train_target, out.detach().numpy()[:, 0]))\n",
        "                train_y_target = numpy.concatenate((train_y_target, d.y.detach().numpy()))\n",
        "\n",
        "        train_loss[epoch] = epoch_loss.detach().numpy()\n",
        "        val_loss[epoch] = v_loss.detach().numpy()\n",
        "\n",
        "        # print current train and val loss\n",
        "        if epoch % 2 == 0:\n",
        "            print(\n",
        "                \"Epoch: \"\n",
        "                + str(epoch)\n",
        "                + \", Train loss: \"\n",
        "                + str(epoch_loss.item())\n",
        "                + \", Val loss: \"\n",
        "                + str(v_loss.item())\n",
        "            )\n",
        "    return train_loss, val_loss, train_target, train_y_target"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gd4Q1dMHFzSs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "model = GCN(dim_h=128)\n",
        "\n",
        "gcn_train_loss, gcn_val_loss, gcn_train_target, gcn_train_y_target = train_epochs(\n",
        "    epochs, model, train_loader, test_loader, \"GCN_model.pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "f9wg3bwcF_SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(gcn_train_loss, gcn_val_loss, gin_train_loss, gin_val_loss):\n",
        "    \"\"\"Plot the loss for each epoch\n",
        "\n",
        "    Args:\n",
        "        epochs (int): number of epochs\n",
        "        train_loss (array): training losses for each epoch\n",
        "        val_loss (array): validation losses for each epoch\n",
        "    \"\"\"\n",
        "    plt.plot(gcn_train_loss, label=\"Train loss (GCN)\")\n",
        "    plt.plot(gcn_val_loss, label=\"Val loss (GCN)\")\n",
        "    plt.plot(gin_train_loss, label=\"Train loss (GIN)\")\n",
        "    plt.plot(gin_val_loss, label=\"Val loss (GIN)\")\n",
        "    plt.legend()\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.title(\"Model Loss\")\n",
        "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.show()\n",
        "\n",
        "def plot_targets(pred, ground_truth):\n",
        "    \"\"\"Plot true vs predicted value in a scatter plot\n",
        "\n",
        "    Args:\n",
        "        pred (array): predicted values\n",
        "        ground_truth (array): ground truth values\n",
        "    \"\"\"\n",
        "    f, ax = plt.subplots(figsize=(6, 6))\n",
        "    ax.scatter(pred, ground_truth, s=0.5)\n",
        "    plt.xlim(-2, 7)\n",
        "    plt.ylim(-2, 7)\n",
        "    ax.axline((1, 1), slope=1)\n",
        "    plt.xlabel(\"Predicted Value\")\n",
        "    plt.ylabel(\"Ground truth\")\n",
        "    plt.title(\"Ground truth vs prediction\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A7vHlcYmGRPJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot overall losses of GIN and GCN\n",
        "\n",
        "plot_loss(gcn_train_loss, gcn_val_loss, gin_train_loss, gin_val_loss)"
      ],
      "metadata": {
        "id": "SvH8m2uGGUd8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}